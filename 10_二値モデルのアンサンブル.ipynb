{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = {\n",
    "    'n_estimators': [1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'random_state': [71],\n",
    "    'min_samples_leaf': sp.stats.randint(3, 30),\n",
    "    'min_samples_split': sp.stats.randint(3, 30),\n",
    "    'max_depth': sp.stats.randint(3, 5),\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "search_parameters = {\n",
    "    'estimator': RandomForestClassifier(),\n",
    "    'param_distributions': model_parameters,\n",
    "    'scoring': 'accuracy',\n",
    "    'cv': 3,\n",
    "    'n_iter': 2,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 71,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは普通に3つのモデルを用意する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df1 = pd.DataFrame(data['data'] , columns=data['feature_names'])\n",
    "_df2 = pd.DataFrame(data['target'], columns=['target'])\n",
    "df = pd.concat([_df1, _df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['target'], prefix='target_')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>target__0</th>\n",
       "      <th>target__1</th>\n",
       "      <th>target__2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  target__0  target__1  target__2  \n",
       "0       0          1          0          0  \n",
       "1       0          1          0          0  \n",
       "2       0          1          0          0  \n",
       "3       0          1          0          0  \n",
       "4       0          1          0          0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['sepal length (cm)', 'sepal width (cm)']], df['target__0'], test_size=0.3, random_state=71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs0 = RandomizedSearchCV(**search_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10], 'criterion': ['gini', 'entropy'], 'random_state': [71], 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d485f60>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d45f0b8>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d45f208>, 'class_weight': [None]},\n",
       "          pre_dispatch='2*n_jobs', random_state=5, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.97      0.90        69\n",
      "          1       0.92      0.64      0.75        36\n",
      "\n",
      "avg / total       0.87      0.86      0.85       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91        31\n",
      "          1       0.90      0.64      0.75        14\n",
      "\n",
      "avg / total       0.87      0.87      0.86        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, rs.predict(X_train)))\n",
    "print(classification_report(y_test, rs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=2, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [1000], 'criterion': ['gini', 'entropy'], 'random_state': [71], 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d486470>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d486780>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d486630>, 'class_weight': [None, 'balanced']},\n",
       "          pre_dispatch='2*n_jobs', random_state=71, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['sepal length (cm)', 'sepal width (cm)']], df['target__1'], test_size=0.3, random_state=71)\n",
    "rs1 = RandomizedSearchCV(**search_parameters)\n",
    "rs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87        73\n",
      "          1       0.73      0.59      0.66        32\n",
      "\n",
      "avg / total       0.80      0.81      0.80       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.93      0.82        27\n",
      "          1       0.82      0.50      0.62        18\n",
      "\n",
      "avg / total       0.77      0.76      0.74        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, rs1.predict(X_train)))\n",
    "print(classification_report(y_test, rs1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=2, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [1000], 'criterion': ['gini', 'entropy'], 'random_state': [71], 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d486470>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d486780>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f287d486630>, 'class_weight': [None, 'balanced']},\n",
       "          pre_dispatch='2*n_jobs', random_state=71, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['sepal length (cm)', 'sepal width (cm)']], df['target__2'], test_size=0.3, random_state=71)\n",
    "rs2 = RandomizedSearchCV(**search_parameters)\n",
    "rs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        68\n",
      "          1       0.78      0.78      0.78        37\n",
      "\n",
      "avg / total       0.85      0.85      0.85       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.78      0.85        32\n",
      "          1       0.61      0.85      0.71        13\n",
      "\n",
      "avg / total       0.83      0.80      0.81        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, rs2.predict(X_train)))\n",
    "print(classification_report(y_test, rs2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アンサンブルしてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンサンブルのモデルをさらにアンサンブル...\n",
    "\n",
    "1. yをlistで渡す\n",
    "2. dummies\n",
    "3. 複数モデルを学習するクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    def __init__(self, df, feature_names, target_name, parameters):\n",
    "        self.models = []\n",
    "        self.search_parameters = parameters\n",
    "        \n",
    "        self.feature_names = feature_names\n",
    "        y_df = pd.get_dummies(df[target_name], prefix='y_')\n",
    "        self.y_columns = y_df.columns\n",
    "        _df = pd.concat([df, y_df], axis=1)\n",
    "        self.df = _df\n",
    "    \n",
    "    def fit(self, test_size=0.3):\n",
    "        for y in self.y_columns:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.df[self.feature_names],\n",
    "                                                                self.df[y],\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=71)    \n",
    "            rs = RandomizedSearchCV(** self.search_parameters)\n",
    "            rs.fit(X_train, y_train)\n",
    "            self.models.append(rs)\n",
    "            print('#'*30, y)\n",
    "            print(classification_report(y_train, rs.predict(X_train)))\n",
    "            print(classification_report(y_test, rs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df1 = pd.DataFrame(data['data'] , columns=data['feature_names'])\n",
    "_df2 = pd.DataFrame(data['target'], columns=['target'])\n",
    "df = pd.concat([_df1, _df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
       "       'petal width (cm)', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Ensemble(df, feature_names=df.columns[:2].tolist(),\n",
    "             target_name='target', parameters=search_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## y__0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99        69\n",
      "          1       0.95      1.00      0.97        36\n",
      "\n",
      "avg / total       0.98      0.98      0.98       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.87      0.93        31\n",
      "          1       0.78      1.00      0.88        14\n",
      "\n",
      "avg / total       0.93      0.91      0.91        45\n",
      "\n",
      "############################## y__1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87        73\n",
      "          1       0.73      0.59      0.66        32\n",
      "\n",
      "avg / total       0.80      0.81      0.80       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.93      0.82        27\n",
      "          1       0.82      0.50      0.62        18\n",
      "\n",
      "avg / total       0.77      0.76      0.74        45\n",
      "\n",
      "############################## y__2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88        68\n",
      "          1       0.78      0.78      0.78        37\n",
      "\n",
      "avg / total       0.85      0.85      0.85       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.78      0.85        32\n",
      "          1       0.61      0.85      0.71        13\n",
      "\n",
      "avg / total       0.83      0.80      0.81        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([e.df[e.df.columns[:2]].shape[0], len(e.y_columns)])\n",
    "for idx, m in enumerate(e.models):\n",
    "    predicted = m.predict_proba(e.df[e.df.columns[:2]])\n",
    "    a[:, idx] = predicted[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94        50\n",
      "          1       0.78      0.58      0.67        50\n",
      "          2       0.72      0.82      0.77        50\n",
      "\n",
      "avg / total       0.80      0.80      0.79       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(e.df['target'], np.argmax(a, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上がってはいるかな？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    def __init__(self, df, feature_names, target_name, parameters):\n",
    "        self.models = []\n",
    "        self.search_parameters = parameters\n",
    "        \n",
    "        self.feature_names = feature_names\n",
    "        y_df = pd.get_dummies(df[target_name], prefix='y_')\n",
    "        self.y_columns = y_df.columns\n",
    "        _df = pd.concat([df, y_df], axis=1)\n",
    "        self.df = _df\n",
    "    \n",
    "    def fit(self, test_size=0.3):\n",
    "        for y in self.y_columns:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.df[self.feature_names],\n",
    "                                                                self.df[y],\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=71)    \n",
    "            rs = RandomizedSearchCV(** self.search_parameters)\n",
    "            rs.fit(X_train, y_train)\n",
    "            self.models.append(rs)\n",
    "            print('#'*30, y)\n",
    "            print(classification_report(y_train, rs.predict(X_train)))\n",
    "            print(classification_report(y_test, rs.predict(X_test)))\n",
    "    \n",
    "    def predict(self, X, y):\n",
    "        a = np.zeros([X.shape[0], len(self.y_columns)])\n",
    "        for idx, m in enumerate(self.models):\n",
    "            predicted = m.predict_proba(X)\n",
    "            a[:, idx] = predicted[:, 1]\n",
    "        \n",
    "        print(classification_report(y, np.argmax(a, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## y__0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        69\n",
      "          1       1.00      1.00      1.00        36\n",
      "\n",
      "avg / total       1.00      1.00      1.00       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        31\n",
      "          1       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "############################## y__1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99        73\n",
      "          1       1.00      0.97      0.98        32\n",
      "\n",
      "avg / total       0.99      0.99      0.99       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95        27\n",
      "          1       0.94      0.89      0.91        18\n",
      "\n",
      "avg / total       0.93      0.93      0.93        45\n",
      "\n",
      "############################## y__2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        68\n",
      "          1       0.97      1.00      0.99        37\n",
      "\n",
      "avg / total       0.99      0.99      0.99       105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.95        32\n",
      "          1       0.86      0.92      0.89        13\n",
      "\n",
      "avg / total       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e = Ensemble(df, feature_names=df.columns.tolist()[:4],\n",
    "             target_name='target', parameters=search_parameters)\n",
    "e.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       0.98      0.94      0.96        50\n",
      "          2       0.94      0.98      0.96        50\n",
      "\n",
      "avg / total       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.predict(e.df[e.df.columns[:4]], e.df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
